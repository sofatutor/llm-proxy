version: '3.8'

services:
  llm-proxy:
    build:
      context: .
      dockerfile: Dockerfile
    image: llm-proxy:latest
    container_name: llm-proxy
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - llm-proxy-data:/data
      - llm-proxy-logs:/logs
      - llm-proxy-config:/config
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MANAGEMENT_TOKEN=${MANAGEMENT_TOKEN}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - ENABLE_METRICS=true
      - PORT=${PORT:-8080}
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 5s

volumes:
  llm-proxy-data:
    name: llm-proxy-data
  llm-proxy-logs:
    name: llm-proxy-logs
  llm-proxy-config:
    name: llm-proxy-config
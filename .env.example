# LLM Proxy - Environment Variables
# Copy this file to .env and update the values as needed
# SECURITY WARNING: Never commit the .env file to version control!

# ===== Core Configuration =====

# Management token for admin operations
# REQUIRED: Generate a strong, unique token for administrative access
# SECURITY: Use a secure random generator with at least 32 characters
# Example: openssl rand -base64 32
MANAGEMENT_TOKEN=replace_with_secure_random_token

# Server address to listen on (default: :8080)
LISTEN_ADDR=:8080

# Database settings
# DB_DRIVER: Database driver to use. Options: sqlite, postgres (default: sqlite)
DB_DRIVER=sqlite
# DATABASE_PATH: Path to SQLite database file (used when DB_DRIVER=sqlite)
DATABASE_PATH=./data/llm-proxy.db
# DATABASE_URL: PostgreSQL connection string (used when DB_DRIVER=postgres)
# Format: postgres://user:password@host:port/database?sslmode=require
# Example: postgres://llmproxy:secret@localhost:5432/llmproxy?sslmode=require
# SECURITY: Use sslmode=require for encrypted connections, or sslmode=verify-full
# with CA certs for full certificate validation in production.
# See: https://www.postgresql.org/docs/current/libpq-ssl.html
DATABASE_URL=
# DATABASE_POOL_SIZE: Maximum number of open database connections (default: 10)
DATABASE_POOL_SIZE=10
# DATABASE_MAX_IDLE_CONNS: Maximum number of idle connections (default: 5)
DATABASE_MAX_IDLE_CONNS=5
# DATABASE_CONN_MAX_LIFETIME: Maximum connection lifetime (default: 1h)
DATABASE_CONN_MAX_LIFETIME=1h

# Logging
LOG_LEVEL=info                # Options: debug, info, warn, error
LOG_FORMAT=json               # Options: json, text
LOG_FILE=./data/llm-proxy.log # Set to empty string to log to stdout only

# ===== API Configuration =====

# OpenAI API settings
OPENAI_API_URL=https://api.openai.com
REQUEST_TIMEOUT=30s           # Timeout for upstream API requests
MAX_REQUEST_SIZE=10MB         # Maximum size of incoming requests
ENABLE_STREAMING=true         # Enable support for streaming responses

# ===== Admin UI Configuration =====

# Enable/disable the admin UI
ADMIN_UI_ENABLED=true
ADMIN_UI_PATH=/admin         # Base path for admin UI

# ===== Security Configuration =====

# CORS settings
# SECURITY: For production, specify exact origins instead of wildcard (*)
CORS_ALLOWED_ORIGINS=*
CORS_ALLOWED_METHODS=GET,POST,PUT,DELETE,OPTIONS
CORS_ALLOWED_HEADERS=Authorization,Content-Type
CORS_MAX_AGE=86400

# TLS/HTTPS configuration
# SECURITY: Enable TLS in production environments
ENABLE_TLS=false
TLS_CERT_FILE=./certs/server.crt
TLS_KEY_FILE=./certs/server.key
# SECURITY: Recommended minimum TLS version
TLS_MIN_VERSION=1.2

# Rate limiting
GLOBAL_RATE_LIMIT=100        # Maximum requests per minute globally
IP_RATE_LIMIT=30             # Maximum requests per minute per IP

# Distributed Rate Limiting (Redis-backed)
# Enable for multi-instance deployments to enforce global rate limits
DISTRIBUTED_RATE_LIMIT_ENABLED=false   # Enable Redis-backed distributed rate limiting
DISTRIBUTED_RATE_LIMIT_PREFIX=ratelimit:  # Redis key prefix for rate limit counters
DISTRIBUTED_RATE_LIMIT_WINDOW=1m       # Sliding window duration (e.g., 1m, 30s, 5m)
DISTRIBUTED_RATE_LIMIT_MAX=60          # Maximum requests per window
DISTRIBUTED_RATE_LIMIT_FALLBACK=true   # Fallback to in-memory when Redis unavailable
DISTRIBUTED_RATE_LIMIT_KEY_SECRET=     # HMAC secret for hashing token IDs (security, recommended for production)

# API Key security
# SECURITY: Mask API keys in logs to prevent accidental exposure
MASK_API_KEYS=true
# SECURITY: Validate API key format before usage
VALIDATE_API_KEY_FORMAT=true

# Token security
# SECURITY: Maximum token lifetime (set to 0 for no expiration)
DEFAULT_TOKEN_LIFETIME=30d
# SECURITY: Default maximum requests per token
DEFAULT_TOKEN_REQUEST_LIMIT=5000


# ===== Encryption Configuration =====

# Encryption key for sensitive data at rest (API keys)
# SECURITY: STRONGLY RECOMMENDED for production - protects API keys in the database
# Generate a 32-byte key with: openssl rand -base64 32
# When set, API keys are encrypted with AES-256-GCM and tokens are hashed with SHA-256
# If not set, data is stored in plaintext (NOT recommended for production)
ENCRYPTION_KEY=

# Migration: Run `llm-proxy migrate encrypt` to encrypt existing plaintext data
# This is idempotent and safe to run multiple times

# ===== Advanced Configuration =====

# Performance tuning
MAX_CONCURRENT_REQUESTS=100  # Maximum number of concurrent requests
WORKER_POOL_SIZE=10          # Number of worker goroutines for background tasks

# Monitoring
ENABLE_METRICS=true          # Enable Prometheus metrics endpoint
METRICS_PATH=/metrics        # Path for metrics endpoint

# Cleanup
TOKEN_CLEANUP_INTERVAL=1h    # Interval for cleaning up expired tokens

# Observability middleware
OBSERVABILITY_ENABLED=true      # Enable async observability middleware
OBSERVABILITY_BUFFER_SIZE=100    # Event buffer size

# ===== Event Bus Configuration =====

# Event bus backend: "redis", "redis-streams", or "in-memory"
# - redis: Uses Redis List-based event queue (default)
# - redis-streams: Uses Redis Streams with consumer groups for durable, distributed delivery
# - in-memory: Uses in-memory channel (single-process only)
LLM_PROXY_EVENT_BUS=redis

# Redis connection settings (used by redis and redis-streams backends)
REDIS_ADDR=localhost:6379    # Redis server address
REDIS_DB=0                   # Redis database number

# Redis Streams configuration (only used when LLM_PROXY_EVENT_BUS=redis-streams)
REDIS_STREAM_KEY=llm-proxy-events         # Redis stream key name
REDIS_CONSUMER_GROUP=llm-proxy-dispatchers # Consumer group name
REDIS_CONSUMER_NAME=                       # Consumer name (auto-generated if empty)
REDIS_STREAM_MAX_LEN=10000                # Max stream length (0 = unlimited)
REDIS_STREAM_BLOCK_TIME=5s                # Block timeout for reading messages
REDIS_STREAM_CLAIM_TIME=30s               # Min idle time before claiming pending msgs
REDIS_STREAM_BATCH_SIZE=100               # Batch size for reading messages
